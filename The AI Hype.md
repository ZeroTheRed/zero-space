**Date:** 10-06-2024 18-57
**Tags:** #ai
**Uplink:**

# The AI Hype
### Motivation
To gain a proper and well-rounded perspective on AI and whether the hype is justified or is just plain stupid

### Notes
The hype surrounding AI has been getting worse and worse with each coming year. Although AI has been around for several years, the craze picked up momentum only after the release of GPT-3 (or ChatGPT) by OpenAI during 2022

Ever since then, the hype is spinning out of control, a lot of companies are riding on abusing the AI buzzword without really knowing what it actually is, and its limitations, several job openings require experience in AI and ML, and a humongous number of material on AI is emerging, the quality of which is debatable

This video by [Internet of Bugs on AI hype](https://www.youtube.com/watch?v=VctsqOo8wsc) popped up on my home feed just today. I thought that I would see a summary of the AI hype and what Carl (the YouTuber himself) thinks about it. His career in software development spanned 35 years, so that makes him a credible authority to talk about the subject

There are two ends of the AI hype right now
> Those who see AGI show up in a few years, with anthropomorphic robots with roughly human-like intelligence being available for the cost of a luxury car

> Those who consider LLMs to be dead soon enough

He says that the truth is somewhere in between, and I tend to agree. Extreme opinions are generally not backed up with evidence and more often than not, they are sensationalist and fearmongering in nature. There are two sides of every coin and we cannot pay attention to only one of them
What's the best way to get some clarity on the topic? Which way is the world actually headed? Truthfully, we don't know, and Carl says that as well. Companies are making bets, that's all there is. We don't really have exact statistics on the hires and fires, for one. We don't know the motive behind company "restructuring" with AI on the large

- Start with the fundamentals and the ground truth that we know so far
- Use that knowledge to think about how things will look like in the future

GPT-4o's multimodal capability (especially voice chats) isn't anything new. The disruption potential of AI depends on the following
- Are the tasks complex in nature? AI handling simple tasks isn't really a disruption when the same tasks can be handled by humans and is within our present scope
- Are the tasks done correctly? AI would be powerful if it can work on and improve tasks that have maxed out what we as humans can do. If we failed to do the task in the first place not due to unavoidable human limitations alone, then humans can fix the failure too

What counts as evidence?
- Peer-reviewed research papers 
- Benchmarks
- First-hand experience (Unbiased sources with experience)
These are good evidence because if anything goes wrong with these, they eventually get found out, so they are self-regulated in a way. Also, researchers often use benchmarks in their publications. The two sources of evidence support each other, thus making both of them strong sources

This isn't about technology alone at this point - Psychologists and philosophers are also weighing in, but are they qualified enough to speak about this matter? Yes, albeit from a different perspective - *They are examining how humans react to the technology*. The ELIZA effect is important

We believe non-human things have human attributes to them and LLMs (for one) are solidifying that belief
> Powerful delusional beliefs induced in humans by AI chatbots that is a "slow-acting poison"

Dark Patterns have just gained momentum in research, especially about dark patterns in chatbots. In essence, LLMs are designed in ways to make them "appear intelligent" to us humans, and it is true. People are falling for that trap already!

* Tesla faked self-driving demo in 2016
* Google faked their Duplex AI and Gemini AI demos (2018 - 2023)
* Google DeepMind failed the trifecta of novelty, utility, and credibility (as opposed to its claims)
* Amazon's "Just Walk Out" check-out technology was actually thousands of remote workers in India (Mechanical Turk)
* GM's self-driving tech used 1.5 workers/vehicle (1.5??)
* Microsoft's AI tech was used to create deepfake porn videos of Taylor Swift. Apparently, an AI engineering leader at MS discovered critical vulnerabilities in the safety mechanisms of OpenAI's DALL-E 3 but his attempts to bring public attention to the issue were impeded
* Rabbit R1 is basically a total failure (it's just an Android app)
* The Humane Ai Pin gave false info in its demo (MKBHD called it the worst product he has ever reviewed)
* OpenAI reported that GPT-4 ranked in the 90th percentile in zero-shot when taking the uniform bar exam. What was actually the case? It ranked 15th percentile along with people taking the exam for the first time
* One of Sora's demo videos was done by a group called "Shy Kids"
* Devin AI being a lie
**A LOT of demos lie!**

SEC's "AI Washing"