>[!Definition]
>An *embedding model* converts data chunks into numerical vectors

Embedding models -> encode data such as *words, sentences, graphics*, and other information into *multidimensional numerical vectors* that capture its meaning in a way that is easy for a machine to understand
**Input**: Data modalities (text, graphics, video, sentences etc.)
**Output**: Numerical vectors (added to [[Vector Database]])

Examples of embedding models are **Word2Vec** and **BERT**

>[!info]
>Items are that *similar in meaning* are more closely positioned in a well-trained embedding model

Where are embedding models used?
- Natural Language Processing (NLP)
	- Sentimental Analysis
	- Text Classification
	- Machine Translation
	- [[LLMs|Large Language Models]]

